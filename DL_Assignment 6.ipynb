{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0fb5af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-02 18:42:38.831428: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-02 18:42:38.923725: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-02 18:42:40.011762: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-02 18:42:40.568092: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-02 18:42:41.118960: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-02 18:42:41.277507: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-02 18:42:42.389324: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-02 18:42:48.501073: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7df07ee-cffe-4948-a1a0-3c4b3ef01d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow-datasets in /home/aniket/.local/lib/python3.10/site-packages (4.9.6)\n",
      "Requirement already satisfied: absl-py in /home/aniket/.local/lib/python3.10/site-packages (from tensorflow-datasets) (2.1.0)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from tensorflow-datasets) (8.0.3)\n",
      "Requirement already satisfied: dm-tree in /home/aniket/.local/lib/python3.10/site-packages (from tensorflow-datasets) (0.1.8)\n",
      "Requirement already satisfied: immutabledict in /home/aniket/.local/lib/python3.10/site-packages (from tensorflow-datasets) (4.2.0)\n",
      "Requirement already satisfied: numpy in /home/aniket/.local/lib/python3.10/site-packages (from tensorflow-datasets) (1.26.4)\n",
      "Requirement already satisfied: promise in /home/aniket/.local/lib/python3.10/site-packages (from tensorflow-datasets) (2.3)\n",
      "Requirement already satisfied: protobuf>=3.20 in /home/aniket/.local/lib/python3.10/site-packages (from tensorflow-datasets) (3.20.3)\n",
      "Requirement already satisfied: psutil in /home/aniket/.local/lib/python3.10/site-packages (from tensorflow-datasets) (5.9.5)\n",
      "Requirement already satisfied: pyarrow in /home/aniket/.local/lib/python3.10/site-packages (from tensorflow-datasets) (17.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/aniket/.local/lib/python3.10/site-packages (from tensorflow-datasets) (2.31.0)\n",
      "Requirement already satisfied: simple-parsing in /home/aniket/.local/lib/python3.10/site-packages (from tensorflow-datasets) (0.1.6)\n",
      "Requirement already satisfied: tensorflow-metadata in /home/aniket/.local/lib/python3.10/site-packages (from tensorflow-datasets) (1.16.0)\n",
      "Requirement already satisfied: termcolor in /home/aniket/.local/lib/python3.10/site-packages (from tensorflow-datasets) (2.5.0)\n",
      "Requirement already satisfied: toml in /usr/lib/python3/dist-packages (from tensorflow-datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /home/aniket/.local/lib/python3.10/site-packages (from tensorflow-datasets) (4.66.4)\n",
      "Requirement already satisfied: wrapt in /home/aniket/.local/lib/python3.10/site-packages (from tensorflow-datasets) (1.16.0)\n",
      "Requirement already satisfied: array-record>=0.5.0 in /home/aniket/.local/lib/python3.10/site-packages (from tensorflow-datasets) (0.5.1)\n",
      "Requirement already satisfied: etils>=1.6.0 in /home/aniket/.local/lib/python3.10/site-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (1.9.4)\n",
      "Requirement already satisfied: typing_extensions in /home/aniket/.local/lib/python3.10/site-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (4.7.1)\n",
      "Requirement already satisfied: fsspec in /home/aniket/.local/lib/python3.10/site-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (2024.9.0)\n",
      "Requirement already satisfied: importlib_resources in /home/aniket/.local/lib/python3.10/site-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (6.4.5)\n",
      "Requirement already satisfied: zipp in /usr/lib/python3/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/aniket/.local/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.19.0->tensorflow-datasets) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2020.6.20)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from promise->tensorflow-datasets) (1.16.0)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /home/aniket/.local/lib/python3.10/site-packages (from simple-parsing->tensorflow-datasets) (0.16)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9b79a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading images and labels\n",
    "import tensorflow_datasets as tfds  # Correct import\n",
    "\n",
    "# Loading images and labels from the 'tf_flowers' dataset\n",
    "(train_ds, train_labels), (test_ds, test_labels) = tfds.load(\n",
    "    \"tf_flowers\",\n",
    "    split=[\"train[:70%]\", \"train[70%:]\"],  # 70% for training, 30% for testing\n",
    "    batch_size=-1,\n",
    "    as_supervised=True  # Include labels\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fecc74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check existing image size\n",
    "train_ds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02e2aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Resizing images\n",
    "train_ds = tf.image.resize(train_ds, (150, 150))\n",
    "test_ds = tf.image.resize(test_ds, (150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4e55ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4075df27",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transforming labels to correct format\n",
    "train_labels = to_categorical(train_labels, num_classes=5)\n",
    "test_labels = to_categorical(test_labels, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe62aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd015b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2eef28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f77a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading VGG16 model\n",
    "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=train_ds[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9b7212",
   "metadata": {},
   "outputs": [],
   "source": [
    "## will not train base mode\n",
    "# Freeze Parameters in model's lower convolutional layers\n",
    "base_model.trainable = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7117cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing input\n",
    "train_ds = preprocess_input(train_ds) \n",
    "test_ds = preprocess_input(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a215ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model details\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a36121",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add our layers on top of this model\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "flatten_layer = layers.Flatten()\n",
    "dense_layer_1 = layers.Dense(50, activation='relu')\n",
    "dense_layer_2 = layers.Dense(20, activation='relu')\n",
    "prediction_layer = layers.Dense(5, activation='softmax')\n",
    "\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    flatten_layer,\n",
    "    dense_layer_1,\n",
    "    dense_layer_2,\n",
    "    prediction_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb182a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e897abf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9df8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(train_ds, train_labels, epochs=2, validation_split=0.2, batch_size=32, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6451b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "los,accurac=model.evaluate(test_ds,test_labels)\n",
    "print(\"Loss: \",los,\"Accuracy: \", accurac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb2a2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('ACCURACY')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'],loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07be2048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "y_pred = model.predict(test_ds)\n",
    "y_classes = [np.argmax(element) for element in y_pred]\n",
    "#to_categorical(y_classes, num_classes=5)\n",
    "#to_categorical(test_labels, num_classes=5)\n",
    "print(y_classes[:10])\n",
    "print(\"\\nTest\")\n",
    "print(test_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2592a162-e564-48b9-8cf4-39e66ca3a142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975bcbcf-278e-4c9b-857b-0a045d774c93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
